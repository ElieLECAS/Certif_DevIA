#!/usr/bin/env python3
"""
Service pour traiter les fichiers LOG depuis un dossier partag√©
et les sauvegarder dans une base de donn√©es PostgreSQL.

Ce service fait les choses suivantes:
1. Initialise automatiquement la structure de dossiers n√©cessaire
2. Lit les fichiers LOG depuis le dossier logs partag√© (SFTP accessible)
3. Analyse le contenu des fichiers LOG
4. Sauvegarde les donn√©es dans PostgreSQL
5. Supprime les fichiers trait√©s du dossier (optionnel)

Structure de dossiers attendue:
/app/logs/
‚îú‚îÄ‚îÄ DEM12/     # Machines DEM12
‚îú‚îÄ‚îÄ DEMALU/    # Machines DEMALU
‚îî‚îÄ‚îÄ SU12/      # Machines SU12

Utilisation:
- python ftp_log_service.py        # Traitement normal
- python ftp_log_service.py init   # Initialisation structure seulement
"""

import os
import re
import glob
from datetime import datetime, timedelta
import psycopg2
from decimal import Decimal
import logging
from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()

# Configuration du syst√®me de logs pour voir ce qui se passe
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LogService:
    """
    Classe principale qui g√®re tout le processus de traitement des logs locaux.
    
    Cette classe fait le lien entre:
    - Le dossier logs partag√© (o√π sont stock√©s les fichiers LOG)
    - La base de donn√©es PostgreSQL (o√π on sauvegarde les donn√©es)
    """
    
    def __init__(self):
        """
        Initialise le service avec toutes les configurations n√©cessaires.
        Les valeurs par d√©faut peuvent √™tre surcharg√©es par des variables d'environnement.
        """
        # Configuration du dossier de logs (partag√© avec SFTP)
        self.logs_directory = os.getenv('LOGS_DIRECTORY', '/app/logs')
        
        # Configuration pour se connecter √† la base de donn√©es
        self.db_host = os.getenv('POSTGRES_HOST')
        self.db_name = os.getenv('POSTGRES_DB')
        self.db_user = os.getenv('POSTGRES_USER')
        self.db_pass = os.getenv('POSTGRES_PASSWORD')
        
        # Dictionnaire qui fait le lien entre les noms de dossiers et les types de machines
        # Cl√© = nom du dossier dans logs, Valeur = type de machine
        self.cu_directories = {
            'DEM12': 'DEM12',
            'DEMALU': 'DEMALU', 
            'SU12': 'SU12'
        }
        
        # Variables pour stocker les connexions (initialis√©es √† None)
        self.conn = None  # Connexion √† la base de donn√©es
        self.cur = None   # Curseur pour ex√©cuter les requ√™tes SQL

    def connect_db(self):
        """
        Se connecte √† la base de donn√©es PostgreSQL.
        
        Returns:
            bool: True si la connexion r√©ussit, False sinon
        """
        try:
            logger.info("Tentative de connexion √† la base de donn√©es...")
            
            # Cr√©er la connexion avec les param√®tres configur√©s
            self.conn = psycopg2.connect(
                host=self.db_host,
                database=self.db_name,
                user=self.db_user,
                password=self.db_pass
            )
            
            # Cr√©er un curseur pour ex√©cuter les requ√™tes
            self.cur = self.conn.cursor()
            
            logger.info("‚úÖ Connexion √† la base de donn√©es r√©ussie")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la connexion √† la base de donn√©es: {e}")
            return False

    def create_tables(self):
        """
        Cr√©e toutes les tables n√©cessaires dans la base de donn√©es si elles n'existent pas d√©j√†.
        
        Structure des tables:
        - centre_usinage: informations sur chaque machine
        - session_production: donn√©es de production pour chaque jour
        - job_profil: d√©tails des profils de jobs
        - periode_attente: p√©riodes o√π la machine attend
        - periode_arret: p√©riodes o√π la machine est arr√™t√©e
        - piece_production: d√©tails de chaque pi√®ce produite
        
        Returns:
            bool: True si toutes les tables sont cr√©√©es, False sinon
        """
        try:
            logger.info("Cr√©ation des tables de la base de donn√©es...")
            
            # Table pour stocker les informations sur chaque centre d'usinage (machine)
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS centre_usinage (
                    id SERIAL PRIMARY KEY,
                    nom VARCHAR(100) UNIQUE NOT NULL,
                    type_cu VARCHAR(50) NOT NULL,
                    description TEXT,
                    actif BOOLEAN DEFAULT TRUE,
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # Table pour stocker les donn√©es de production de chaque jour
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS session_production (
                    id SERIAL PRIMARY KEY,
                    centre_usinage_id INTEGER REFERENCES centre_usinage(id),
                    date_production DATE NOT NULL,
                    heure_premiere_piece TIMESTAMP,
                    heure_derniere_piece TIMESTAMP,
                    heure_premier_machine_start TIMESTAMP,
                    heure_dernier_machine_stop TIMESTAMP,
                    total_pieces INTEGER DEFAULT 0,
                    duree_production_totale DECIMAL(10,4),
                    temps_attente DECIMAL(10,4),
                    temps_arret_volontaire DECIMAL(10,4),
                    temps_production_effectif DECIMAL(10,4),
                    taux_occupation DECIMAL(5,2),
                    taux_attente DECIMAL(5,2),
                    taux_arret_volontaire DECIMAL(5,2),
                    fichier_log_source VARCHAR(255),
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(centre_usinage_id, date_production)
                );
            """)
            
            # Table pour stocker les profils de jobs
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS job_profil (
                    id SERIAL PRIMARY KEY,
                    session_id INTEGER REFERENCES session_production(id),
                    reference VARCHAR(50) NOT NULL,
                    longueur DECIMAL(10,2),
                    couleur VARCHAR(50),
                    timestamp_debut TIMESTAMP,
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # Table pour stocker les p√©riodes d'attente
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS periode_attente (
                    id SERIAL PRIMARY KEY,
                    session_id INTEGER REFERENCES session_production(id),
                    timestamp_debut TIMESTAMP NOT NULL,
                    timestamp_fin TIMESTAMP NOT NULL,
                    duree_secondes INTEGER NOT NULL,
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # Table pour stocker les p√©riodes d'arr√™t
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS periode_arret (
                    id SERIAL PRIMARY KEY,
                    session_id INTEGER REFERENCES session_production(id),
                    timestamp_debut TIMESTAMP NOT NULL,
                    timestamp_fin TIMESTAMP NOT NULL,
                    duree_secondes INTEGER NOT NULL,
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # Table pour stocker chaque pi√®ce produite
            self.cur.execute("""
                CREATE TABLE IF NOT EXISTS piece_production (
                    id SERIAL PRIMARY KEY,
                    session_id INTEGER REFERENCES session_production(id),
                    numero_piece INTEGER NOT NULL,
                    timestamp_production TIMESTAMP NOT NULL,
                    details TEXT,
                    date_creation TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # Sauvegarder toutes les modifications
            self.conn.commit()
            logger.info("‚úÖ Toutes les tables ont √©t√© cr√©√©es avec succ√®s")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la cr√©ation des tables: {e}")
            return False

    def create_logs_structure(self):
        """
        Cr√©e la structure de dossiers n√©cessaire pour le traitement des logs.
        """
        try:
            logger.info("üöÄ Initialisation de la structure de dossiers logs")
            
            # Cr√©er le dossier principal s'il n'existe pas
            if not os.path.exists(self.logs_directory):
                os.makedirs(self.logs_directory)
                logger.info(f"‚úÖ Dossier principal cr√©√©: {self.logs_directory}")
            else:
                logger.info(f"‚úÖ Dossier principal existant: {self.logs_directory}")
            
            # Cr√©er chaque sous-dossier requis
            for directory_name in self.cu_directories.keys():
                directory_path = os.path.join(self.logs_directory, directory_name)
                
                if not os.path.exists(directory_path):
                    os.makedirs(directory_path)
                    logger.info(f"‚úÖ Dossier cr√©√©: {directory_name}")
                else:
                    logger.info(f"‚úÖ Dossier existant: {directory_name}")
            
            logger.info("üéâ Structure de dossiers initialis√©e avec succ√®s!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation: {e}")
            return False

    def check_logs_directory(self):
        """
        V√©rifie que le dossier de logs existe et cr√©e la structure si n√©cessaire.
        
        Returns:
            bool: True si le dossier existe, False sinon
        """
        try:
            logger.info(f"V√©rification du dossier de logs: {self.logs_directory}")
            
            # Cr√©er la structure de dossiers d'abord
            if not self.create_logs_structure():
                return False
            
            if os.path.exists(self.logs_directory) and os.path.isdir(self.logs_directory):
                logger.info("‚úÖ Dossier de logs accessible")
                return True
            else:
                logger.error(f"‚ùå Dossier de logs non trouv√©: {self.logs_directory}")
                return False
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la v√©rification du dossier de logs: {e}")
            return False

    def get_cu_directories_from_logs(self):
        """
        R√©cup√®re la liste des dossiers de centres d'usinage disponibles dans le dossier logs.
        
        Returns:
            list: Liste des noms de dossiers trouv√©s
        """
        try:
            logger.info("Recherche des dossiers de centres d'usinage...")
            
            # R√©cup√©rer tous les dossiers dans le r√©pertoire logs
            all_dirs = []
            if os.path.exists(self.logs_directory):
                all_dirs = [d for d in os.listdir(self.logs_directory) 
                           if os.path.isdir(os.path.join(self.logs_directory, d))]
            
            cu_dirs = []
            
            # V√©rifier quels dossiers correspondent √† nos centres d'usinage configur√©s
            for directory in all_dirs:
                if directory in self.cu_directories:
                    cu_dirs.append(directory)
                    cu_type = self.cu_directories[directory]
                    logger.info(f"‚úÖ Dossier trouv√©: {directory} -> Type: {cu_type}")
            
            # Afficher un avertissement si aucun dossier n'est trouv√©
            if not cu_dirs:
                logger.warning("‚ö†Ô∏è Aucun dossier de centre d'usinage trouv√©")
                logger.info(f"Dossiers disponibles: {all_dirs}")
                logger.info(f"Dossiers attendus: {list(self.cu_directories.keys())}")
            
            return cu_dirs
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des dossiers: {e}")
            return []

    def get_log_files_from_directory(self, directory):
        """
        R√©cup√®re la liste des fichiers LOG dans un dossier sp√©cifique.
        
        Args:
            directory: Nom du dossier √† explorer
            
        Returns:
            list: Liste des noms de fichiers LOG trouv√©s
        """
        try:
            logger.info(f"Recherche des fichiers LOG dans le dossier: {directory}")
            
            # Construire le chemin complet du dossier
            directory_path = os.path.join(self.logs_directory, directory)
            
            if not os.path.exists(directory_path):
                logger.warning(f"‚ö†Ô∏è Dossier non trouv√©: {directory_path}")
                return []
            
            # R√©cup√©rer tous les fichiers qui se terminent par .LOG
            log_files = []
            for file in os.listdir(directory_path):
                if file.endswith('.LOG') and os.path.isfile(os.path.join(directory_path, file)):
                    log_files.append(file)
            
            logger.info(f"‚úÖ Trouv√© {len(log_files)} fichiers LOG dans {directory}")
            return log_files
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des fichiers de {directory}: {e}")
            return []

    def read_log_file_from_directory(self, directory, filename):
        """
        Lit un fichier LOG depuis un dossier sp√©cifique.
        
        Args:
            directory: Nom du dossier contenant le fichier
            filename: Nom du fichier √† lire
            
        Returns:
            str: Contenu du fichier LOG ou None si erreur
        """
        try:
            logger.info(f"Lecture du fichier: {directory}/{filename}")
            
            # Construire le chemin complet du fichier
            file_path = os.path.join(self.logs_directory, directory, filename)
            
            if not os.path.exists(file_path):
                logger.error(f"‚ùå Fichier non trouv√©: {file_path}")
                return None
            
            # Lire le fichier en mode binaire puis d√©coder
            with open(file_path, 'rb') as file:
                log_content_bytes = file.read()
            
            # Convertir les bytes en texte (utiliser latin-1 qui accepte tous les caract√®res)
            log_content = log_content_bytes.decode('latin-1')
            
            logger.info(f"‚úÖ Fichier lu: {len(log_content)} caract√®res")
            return log_content
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la lecture de {directory}/{filename}: {e}")
            return None

    def delete_log_file_from_directory(self, directory, filename):
        """
        Supprime un fichier LOG d'un dossier sp√©cifique.
        
        Args:
            directory: Nom du dossier contenant le fichier
            filename: Nom du fichier √† supprimer
            
        Returns:
            bool: True si la suppression r√©ussit, False sinon
        """
        try:
            logger.info(f"Suppression du fichier: {directory}/{filename}")
            
            # Construire le chemin complet du fichier
            file_path = os.path.join(self.logs_directory, directory, filename)
            
            if not os.path.exists(file_path):
                logger.warning(f"‚ö†Ô∏è Fichier non trouv√© pour suppression: {file_path}")
                return False
            
            # Supprimer le fichier
            os.remove(file_path)
            
            logger.info(f"‚úÖ Fichier supprim√©: {directory}/{filename}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la suppression de {directory}/{filename}: {e}")
            return False

    def parse_log_content(self, log_content, filename):
        """
        Analyse le contenu d'un fichier LOG et extrait les √©v√©nements.
        
        Format attendu des lignes: YYYYMMDD HH:MM:SS|@EventType: Details
        
        Args:
            log_content: Contenu du fichier LOG sous forme de texte
            filename: Nom du fichier (pour les messages de log)
            
        Returns:
            list: Liste de dictionnaires contenant les √©v√©nements pars√©s
        """
        try:
            logger.info(f"Analyse du contenu du fichier: {filename}")
            
            # Nettoyer le contenu si c'est des bytes
            if isinstance(log_content, bytes):
                log_content = log_content.decode('latin-1')
            
            # Supprimer les caract√®res probl√©matiques
            log_content = log_content.replace('\x00', '')  # Supprimer les caract√®res null
            
            # Diviser le contenu en lignes
            lines = log_content.strip().split('\n')
            data = []
            
            # Analyser chaque ligne
            for line in lines:
                line = line.strip()
                
                # Ignorer les lignes vides ou qui ne contiennent pas le s√©parateur
                if not line or '|@' not in line:
                    continue
                
                try:
                    # Diviser la ligne en timestamp et √©v√©nement
                    timestamp_str, event_part = line.split('|@', 1)
                    
                    # Nettoyer le timestamp
                    timestamp_str = timestamp_str.strip()
                    # Garder seulement les caract√®res ASCII pour le timestamp
                    timestamp_str = ''.join(c for c in timestamp_str if ord(c) < 128)
                    
                    # Convertir le timestamp en objet datetime
                    timestamp = datetime.strptime(timestamp_str, '%Y%m%d %H:%M:%S')
                    
                    # Analyser la partie √©v√©nement
                    if ':' in event_part:
                        event_type, details = event_part.split(':', 1)
                        event_type = event_type.strip()
                        details = details.strip()
                    else:
                        event_type = event_part.strip()
                        details = ""
                    
                    # Ajouter l'√©v√©nement √† notre liste
                    data.append({
                        "Timestamp": timestamp,
                        "Event": event_type,
                        "Details": details
                    })
                    
                except Exception as e:
                    # Ignorer les lignes qui ne peuvent pas √™tre pars√©es
                    continue
            
            if not data:
                logger.warning(f"‚ö†Ô∏è Aucune donn√©e trouv√©e dans {filename}")
                return []
                
            logger.info(f"‚úÖ Fichier {filename} analys√©: {len(data)} √©v√©nements trouv√©s")
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'analyse de {filename}: {e}")
            return []

    def analyze_machine_performance(self, data, log_file_name, cu_type):
        """
        Analyse les performances d'une machine √† partir des √©v√©nements du log.
        
        Cette fonction calcule:
        - Le nombre de pi√®ces produites
        - Les temps de production, d'attente et d'arr√™t
        - Les taux d'occupation
        - Les d√©tails des jobs et p√©riodes
        
        Args:
            data: Liste des √©v√©nements pars√©s
            log_file_name: Nom du fichier LOG
            cu_type: Type de centre d'usinage (PVC, ALU, HYBRIDE)
            
        Returns:
            dict: Dictionnaire contenant toutes les m√©triques calcul√©es
        """
        if not data:
            logger.warning("Aucune donn√©e √† analyser")
            return None
        
        logger.info(f"Analyse des performances pour {log_file_name} (Type: {cu_type})")
        
        # Extraire la date du premier √©v√©nement
        log_date = data[0]["Timestamp"].date()
        
        # Cr√©er un identifiant unique pour ce centre d'usinage
        cu_id = f"{cu_type}_{os.path.splitext(log_file_name)[0]}"
        
        # === ANALYSE DES PI√àCES PRODUITES ===
        # Chercher tous les √©v√©nements "StukUitgevoerd" (pi√®ce termin√©e)
        stuk_events = [event for event in data if event["Event"] == "StukUitgevoerd"]
        
        # Calculer les temps de premi√®re et derni√®re pi√®ce
        first_piece_time = stuk_events[0]["Timestamp"] if stuk_events else None
        last_piece_time = stuk_events[-1]["Timestamp"] if stuk_events else None
        total_pieces = len(stuk_events)
        
        # Calculer la dur√©e totale de production
        production_duration = None
        if first_piece_time and last_piece_time:
            production_duration = (last_piece_time - first_piece_time).total_seconds() / 3600  # en heures
        
        # === ANALYSE DES TEMPS D'ATTENTE ===
        # Chercher tous les √©v√©nements "MachineWait"
        wait_events = [event for event in data if event["Event"] == "MachineWait"]
        
        total_wait_time = 0  # en secondes
        wait_periods = []
        
        # Analyser chaque p√©riode d'attente
        for event in wait_events:
            try:
                # Chercher la dur√©e dans les d√©tails (format: "X sec" ou "X.X")
                wait_matches = re.findall(r"(\d+) sec", str(event["Details"]))
                wait_duration = 0
                
                if wait_matches:
                    wait_duration = float(wait_matches[0])
                else:
                    # Chercher un nombre d√©cimal
                    decimal_matches = re.findall(r"(\d+\.\d+)", str(event["Details"]))
                    if decimal_matches:
                        wait_duration = float(decimal_matches[0])
                
                if wait_duration > 0:
                    wait_start = event["Timestamp"]
                    wait_end = wait_start + timedelta(seconds=wait_duration)
                    wait_periods.append({
                        "Start": wait_start,
                        "End": wait_end,
                        "Duration": wait_duration
                    })
                    total_wait_time += wait_duration
                    
            except Exception as e:
                # Ignorer les √©v√©nements qui ne peuvent pas √™tre analys√©s
                continue
        
        total_wait_hours = total_wait_time / 3600  # convertir en heures
        
        # === ANALYSE DES ARR√äTS VOLONTAIRES ===
        # Chercher les √©v√©nements de d√©marrage et d'arr√™t de machine
        stop_events = [event for event in data if event["Event"] in ["MachineStop", "MachineStart"]]
        
        # Trouver le dernier arr√™t et le premier d√©marrage
        machine_stop_events = [event for event in data if event["Event"] == "MachineStop"]
        last_machine_stop = machine_stop_events[-1]["Timestamp"] if machine_stop_events else None
        
        machine_start_events = [event for event in data if event["Event"] == "MachineStart"]
        first_machine_start = machine_start_events[0]["Timestamp"] if machine_start_events else None
        
        total_stop_time = 0  # en secondes
        stop_periods = []
        
        # Calculer les p√©riodes d'arr√™t (entre MachineStop et MachineStart)
        if stop_events:
            for i in range(len(stop_events) - 1):
                if (stop_events[i]["Event"] == "MachineStop" and 
                    stop_events[i + 1]["Event"] == "MachineStart"):
                    
                    stop_start = stop_events[i]["Timestamp"]
                    stop_end = stop_events[i + 1]["Timestamp"]
                    stop_duration = (stop_end - stop_start).total_seconds()
                    
                    stop_periods.append({
                        "Start": stop_start,
                        "End": stop_end,
                        "Duration": stop_duration
                    })
                    total_stop_time += stop_duration
        
        total_stop_hours = total_stop_time / 3600  # convertir en heures
        
        # === ANALYSE DES PROFILS DE JOBS ===
        # Chercher tous les √©v√©nements "JobProfiel"
        job_events = [event for event in data if event["Event"] == "JobProfiel"]
        
        job_details = []
        for event in job_events:
            try:
                job = event["Details"]
                # Extraire les informations avec des expressions r√©guli√®res
                ref_match = re.search(r"R:(\w+)", job)      # R√©f√©rence
                length_match = re.search(r"L:(\d+\.\d+)", job)  # Longueur
                color_match = re.search(r"C:(\w+)", job)    # Couleur
                
                if ref_match and length_match:
                    ref = ref_match.group(1)
                    length = float(length_match.group(1))
                    color = color_match.group(1) if color_match else "N/A"
                    timestamp = event["Timestamp"]
                    
                    job_details.append({
                        "Reference": ref,
                        "Length": length,
                        "Color": color,
                        "Timestamp": timestamp
                    })
            except:
                # Ignorer les jobs qui ne peuvent pas √™tre analys√©s
                continue
        
        # === COLLECTE DES D√âTAILS DES PI√àCES ===
        piece_events = []
        for i, event in enumerate(stuk_events):
            piece_events.append({
                "Timestamp": event["Timestamp"],
                "Piece": event["Details"]
            })
        
        # === CALCUL DES INDICATEURS DE PERFORMANCE ===
        if production_duration and production_duration > 0:
            # Temps de production effectif = temps total - attentes - arr√™ts
            effective_production_time = production_duration - total_wait_hours - total_stop_hours
            total_available_time = production_duration
            
            # Calculer les pourcentages
            occupation_rate = (effective_production_time / total_available_time) * 100
            wait_rate = (total_wait_hours / total_available_time) * 100
            stop_rate = (total_stop_hours / total_available_time) * 100
        else:
            effective_production_time = 0
            occupation_rate = 0
            wait_rate = 0
            stop_rate = 0
        
        # === RETOURNER TOUS LES R√âSULTATS ===
        results = {
            "CU_ID": cu_id,
            "Date": log_date,
            "PremierePiece": first_piece_time,
            "DernierePiece": last_piece_time,
            "PremierMachineStart": first_machine_start,
            "DernierMachineStop": last_machine_stop,
            "TotalPieces": total_pieces,
            "DureeProduction": production_duration,
            "TempsAttente": total_wait_hours,
            "TempsArretVolontaire": total_stop_hours,
            "TempsProductionEffectif": effective_production_time,
            "TauxOccupation": occupation_rate,
            "TauxAttente": wait_rate,
            "TauxArretVolontaire": stop_rate,
            "JobDetails": job_details,
            "WaitPeriods": wait_periods,
            "StopPeriods": stop_periods,
            "PieceEvents": piece_events
        }
        
        logger.info(f"‚úÖ Analyse termin√©e: {total_pieces} pi√®ces, {occupation_rate:.1f}% d'occupation")
        return results

    def save_to_database(self, results, cu_type, log_file_name, directory):
        """
        Sauvegarde tous les r√©sultats d'analyse dans la base de donn√©es.
        
        Cette fonction:
        1. Cr√©e ou met √† jour le centre d'usinage
        2. Cr√©e ou met √† jour la session de production
        3. Sauvegarde tous les d√©tails (jobs, p√©riodes, pi√®ces)
        
        Args:
            results: Dictionnaire contenant tous les r√©sultats d'analyse
            cu_type: Type de centre d'usinage
            log_file_name: Nom du fichier LOG source
            directory: Nom du dossier FTP source
            
        Returns:
            bool: True si la sauvegarde r√©ussit, False sinon
        """
        try:
            logger.info(f"Sauvegarde des donn√©es en base pour {cu_type}")
            
            # Cr√©er un nom unique pour ce centre d'usinage
            cu_name = f"{cu_type}_{os.path.splitext(log_file_name)[0]}"
            
            # === √âTAPE 1: CR√âER OU METTRE √Ä JOUR LE CENTRE D'USINAGE ===
            # Approche alternative : v√©rifier s'il existe d√©j√†, sinon l'ins√©rer
            self.cur.execute("""
                SELECT id FROM centre_usinage WHERE nom = %s
            """, (cu_name,))
            
            centre_result = self.cur.fetchone()
            
            if centre_result:
                # Mettre √† jour le centre existant
                centre_usinage_id = centre_result[0]
                self.cur.execute("""
                    UPDATE centre_usinage 
                    SET type_cu = %s, description = %s
                    WHERE id = %s
                """, (cu_type, f'Centre d\'usinage {cu_type} - {directory}', centre_usinage_id))
            else:
                # Cr√©er un nouveau centre
                self.cur.execute("""
                    INSERT INTO centre_usinage (nom, type_cu, description, actif)
                    VALUES (%s, %s, %s, %s)
                    RETURNING id;
                """, (cu_name, cu_type, f'Centre d\'usinage {cu_type} - {directory}', True))
                centre_usinage_id = self.cur.fetchone()[0]
            
            # === √âTAPE 2: CR√âER OU METTRE √Ä JOUR LA SESSION DE PRODUCTION ===
            # Approche alternative : v√©rifier s'il existe d√©j√†, sinon l'ins√©rer
            self.cur.execute("""
                SELECT id FROM session_production 
                WHERE centre_usinage_id = %s AND date_production = %s
            """, (centre_usinage_id, results["Date"]))
            
            session_result = self.cur.fetchone()
            
            if session_result:
                # Mettre √† jour la session existante
                session_id = session_result[0]
                self.cur.execute("""
                    UPDATE session_production SET
                        heure_premiere_piece = %s,
                        heure_derniere_piece = %s,
                        heure_premier_machine_start = %s,
                        heure_dernier_machine_stop = %s,
                        total_pieces = %s,
                        duree_production_totale = %s,
                        temps_attente = %s,
                        temps_arret_volontaire = %s,
                        temps_production_effectif = %s,
                        taux_occupation = %s,
                        taux_attente = %s,
                        taux_arret_volontaire = %s,
                        fichier_log_source = %s
                    WHERE id = %s
                """, (
                    results["PremierePiece"], 
                    results["DernierePiece"],
                    results["PremierMachineStart"], 
                    results["DernierMachineStop"], 
                    results["TotalPieces"],
                    Decimal(str(results["DureeProduction"] or 0)), 
                    Decimal(str(results["TempsAttente"] or 0)),
                    Decimal(str(results["TempsArretVolontaire"] or 0)), 
                    Decimal(str(results["TempsProductionEffectif"] or 0)),
                    Decimal(str(results["TauxOccupation"] or 0)), 
                    Decimal(str(results["TauxAttente"] or 0)),
                    Decimal(str(results["TauxArretVolontaire"] or 0)), 
                    f"{directory}/{log_file_name}",
                    session_id
                ))
            else:
                # Cr√©er une nouvelle session
                self.cur.execute("""
                    INSERT INTO session_production (
                        centre_usinage_id, date_production, heure_premiere_piece, heure_derniere_piece,
                        heure_premier_machine_start, heure_dernier_machine_stop, total_pieces,
                        duree_production_totale, temps_attente, temps_arret_volontaire,
                        temps_production_effectif, taux_occupation, taux_attente,
                        taux_arret_volontaire, fichier_log_source
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    RETURNING id;
                """, (
                    centre_usinage_id, 
                    results["Date"], 
                    results["PremierePiece"], 
                    results["DernierePiece"],
                    results["PremierMachineStart"], 
                    results["DernierMachineStop"], 
                    results["TotalPieces"],
                    Decimal(str(results["DureeProduction"] or 0)), 
                    Decimal(str(results["TempsAttente"] or 0)),
                    Decimal(str(results["TempsArretVolontaire"] or 0)), 
                    Decimal(str(results["TempsProductionEffectif"] or 0)),
                    Decimal(str(results["TauxOccupation"] or 0)), 
                    Decimal(str(results["TauxAttente"] or 0)),
                    Decimal(str(results["TauxArretVolontaire"] or 0)), 
                    f"{directory}/{log_file_name}"
                ))
                session_id = self.cur.fetchone()[0]
            
            # === √âTAPE 3: SUPPRIMER LES ANCIENNES DONN√âES D√âTAILL√âES ===
            # (pour √©viter les doublons si on retraite le m√™me fichier)
            self.cur.execute("DELETE FROM job_profil WHERE session_id = %s", (session_id,))
            self.cur.execute("DELETE FROM periode_attente WHERE session_id = %s", (session_id,))
            self.cur.execute("DELETE FROM periode_arret WHERE session_id = %s", (session_id,))
            self.cur.execute("DELETE FROM piece_production WHERE session_id = %s", (session_id,))
            
            # === √âTAPE 4: SAUVEGARDER LES PROFILS DE JOBS ===
            for job in results["JobDetails"]:
                self.cur.execute("""
                    INSERT INTO job_profil (session_id, reference, longueur, couleur, timestamp_debut)
                    VALUES (%s, %s, %s, %s, %s)
                """, (session_id, job["Reference"], Decimal(str(job["Length"])), job["Color"], job["Timestamp"]))
            
            # === √âTAPE 5: SAUVEGARDER LES P√âRIODES D'ATTENTE ===
            for wait in results["WaitPeriods"]:
                self.cur.execute("""
                    INSERT INTO periode_attente (session_id, timestamp_debut, timestamp_fin, duree_secondes)
                    VALUES (%s, %s, %s, %s)
                """, (session_id, wait["Start"], wait["End"], int(wait["Duration"])))
            
            # === √âTAPE 6: SAUVEGARDER LES P√âRIODES D'ARR√äT ===
            for stop in results["StopPeriods"]:
                self.cur.execute("""
                    INSERT INTO periode_arret (session_id, timestamp_debut, timestamp_fin, duree_secondes)
                    VALUES (%s, %s, %s, %s)
                """, (session_id, stop["Start"], stop["End"], int(stop["Duration"])))
            
            # === √âTAPE 7: SAUVEGARDER LES PI√àCES PRODUITES ===
            for i, piece in enumerate(results["PieceEvents"], 1):
                self.cur.execute("""
                    INSERT INTO piece_production (session_id, numero_piece, timestamp_production, details)
                    VALUES (%s, %s, %s, %s)
                """, (session_id, i, piece["Timestamp"], piece["Piece"]))
            
            # === √âTAPE 8: CONFIRMER TOUTES LES MODIFICATIONS ===
            self.conn.commit()
            logger.info(f"‚úÖ Donn√©es sauvegard√©es avec succ√®s pour {cu_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la sauvegarde: {e}")
            # En cas d'erreur, annuler toutes les modifications
            self.conn.rollback()
            return False

    def process_all_logs(self, delete_after_processing=True):
        """
        Fonction principale qui traite tous les fichiers LOG du dossier partag√©.
        
        Cette fonction:
        1. Se connecte √† la base de donn√©es
        2. V√©rifie l'acc√®s au dossier logs
        3. Cr√©e les tables n√©cessaires
        4. Explore tous les dossiers de centres d'usinage
        5. Traite chaque fichier LOG trouv√©
        6. Supprime les fichiers trait√©s (optionnel)
        
        Args:
            delete_after_processing: Si True, supprime les fichiers apr√®s traitement
            
        Returns:
            bool: True si tout s'est bien pass√©, False s'il y a eu des erreurs
        """
        try:
            logger.info("üöÄ D√âBUT DU TRAITEMENT DE TOUS LES LOGS")
            
            # === √âTAPE 1: √âTABLIR LA CONNEXION BASE DE DONN√âES ===
            if not self.connect_db():
                logger.error("‚ùå Impossible de se connecter √† la base de donn√©es")
                return False
                
            # === √âTAPE 2: V√âRIFIER L'ACC√àS AU DOSSIER LOGS ===
            if not self.check_logs_directory():
                logger.error("‚ùå Impossible d'acc√©der au dossier de logs")
                return False
            
            # === √âTAPE 3: CR√âER LES TABLES ===
            if not self.create_tables():
                logger.error("‚ùå Impossible de cr√©er les tables")
                return False
            
            # === √âTAPE 4: R√âCUP√âRER LES DOSSIERS DE CENTRES D'USINAGE ===
            cu_directories = self.get_cu_directories_from_logs()
            
            if not cu_directories:
                logger.error("‚ùå Aucun dossier de centre d'usinage trouv√©")
                return False
            
            # Variables pour compter les r√©sultats
            total_processed = 0
            total_errors = 0
            
            # === √âTAPE 5: TRAITER CHAQUE DOSSIER ===
            for directory in cu_directories:
                cu_type = self.cu_directories[directory]
                logger.info(f"\nüìÅ === TRAITEMENT DU DOSSIER {directory} (Type: {cu_type}) ===")
                
                # R√©cup√©rer tous les fichiers LOG de ce dossier
                log_files = self.get_log_files_from_directory(directory)
                
                if not log_files:
                    logger.warning(f"‚ö†Ô∏è Aucun fichier LOG trouv√© dans {directory}")
                    continue
                
                # Compteurs pour ce dossier
                processed_count = 0
                error_count = 0
                
                # === √âTAPE 6: TRAITER CHAQUE FICHIER LOG ===
                for filename in log_files:
                    try:
                        logger.info(f"üìÑ Traitement de {directory}/{filename}...")
                        
                        # Lire le fichier depuis le dossier local
                        log_content = self.read_log_file_from_directory(directory, filename)
                        if not log_content:
                            logger.error(f"‚ùå √âchec de la lecture de {filename}")
                            error_count += 1
                            continue
                        
                        # Analyser le contenu du fichier
                        data = self.parse_log_content(log_content, filename)
                        if not data:
                            logger.error(f"‚ùå √âchec de l'analyse de {filename}")
                            error_count += 1
                            continue
                        
                        # Calculer les performances de la machine
                        results = self.analyze_machine_performance(data, filename, cu_type)
                        if not results:
                            logger.error(f"‚ùå √âchec du calcul des performances pour {filename}")
                            error_count += 1
                            continue
                        
                        # Sauvegarder les r√©sultats en base de donn√©es
                        if self.save_to_database(results, cu_type, filename, directory):
                            logger.info(f"‚úÖ {directory}/{filename} trait√© avec succ√®s")
                            
                            # Supprimer le fichier local si demand√©
                            if delete_after_processing:
                                if self.delete_log_file_from_directory(directory, filename):
                                    logger.info(f"üóëÔ∏è Fichier supprim√©")
                                else:
                                    logger.warning(f"‚ö†Ô∏è Fichier trait√© mais non supprim√©")
                            
                            processed_count += 1
                        else:
                            logger.error(f"‚ùå √âchec de la sauvegarde pour {filename}")
                            error_count += 1
                            
                    except Exception as e:
                        logger.error(f"‚ùå Erreur inattendue lors du traitement de {directory}/{filename}: {e}")
                        error_count += 1
                
                # R√©sum√© pour ce dossier
                logger.info(f"üìä Dossier {directory} termin√©: {processed_count} fichiers trait√©s, {error_count} erreurs")
                total_processed += processed_count
                total_errors += error_count
            
            # === R√âSUM√â FINAL ===
            logger.info(f"\nüéØ === TRAITEMENT GLOBAL TERMIN√â ===")
            logger.info(f"üìà Total: {total_processed} fichiers trait√©s avec succ√®s")
            logger.info(f"‚ùå Total: {total_errors} erreurs rencontr√©es")
            
            # Retourner True seulement s'il n'y a eu aucune erreur
            return total_errors == 0
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©rale lors du traitement: {e}")
            return False
        finally:
            # Toujours fermer les connexions √† la fin
            self.close_connections()

    def close_connections(self):
        """
        Ferme proprement toutes les connexions ouvertes.
        Cette fonction est appel√©e automatiquement √† la fin du traitement.
        """
        logger.info("üîå Fermeture des connexions...")
        
        # Fermer le curseur de base de donn√©es
        if self.cur:
            try:
                self.cur.close()
                logger.info("‚úÖ Curseur de base de donn√©es ferm√©")
            except:
                logger.warning("‚ö†Ô∏è Erreur lors de la fermeture du curseur")
        
        # Fermer la connexion √† la base de donn√©es
        if self.conn:
            try:
                self.conn.close()
                logger.info("‚úÖ Connexion √† la base de donn√©es ferm√©e")
            except:
                logger.warning("‚ö†Ô∏è Erreur lors de la fermeture de la base de donn√©es")


def main():
    """
    Fonction principale qui peut √™tre appel√©e directement.
    Utile pour tester le service ou l'ex√©cuter manuellement.
    
    Arguments en ligne de commande:
    - init : Initialise seulement la structure de dossiers
    - process : Traite les logs (par d√©faut)
    """
    import sys
    
    logger.info("üé¨ D√©marrage du service de traitement des logs")
    
    # Cr√©er une instance du service
    service = LogService()
    
    # V√©rifier les arguments de ligne de commande
    if len(sys.argv) > 1 and sys.argv[1] == 'init':
        # Mode initialisation seulement
        logger.info("Mode initialisation demand√©")
        if service.create_logs_structure():
            logger.info("‚ú® Initialisation termin√©e avec succ√®s!")
        else:
            logger.error("üí• Initialisation termin√©e avec des erreurs!")
        return
    
    # Mode traitement normal (par d√©faut)
    # Lire la configuration depuis les variables d'environnement
    delete_after_sync = os.getenv('DELETE_AFTER_SYNC', 'false').lower() == 'true'
    
    # Traiter tous les logs selon la configuration
    success = service.process_all_logs(delete_after_processing=delete_after_sync)
    
    if success:
        logger.info("üéâ Traitement termin√© avec succ√®s!")
    else:
        logger.error("üí• Traitement termin√© avec des erreurs!")


# Point d'entr√©e du script
if __name__ == "__main__":
    main() 